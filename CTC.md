# CTC

## 简介

对于语音识别来说，训练数据的输入是一段音频，输出是它转录的文字(transcript)，但是我们是不知道字母和语音是怎么对齐(align)的。这使得训练语音识别比看起来更加复杂。

要人来标注这种对齐是非常困难而且容易出错的，因为很多音素的边界是很难区分，人通过看波形或者频谱是很难准确的区分其边界的。之前基于HMM的语音识别系统在训练声学模型是需要对齐，我们通常会让模型进行强制对齐(forced alignment)。类似的在手写文字识别中，也会存在同样的问题，虽然看起来比声音简单一下，字母T和h在手写的时候是粘连在一起的，传统的识别方法可以首先需要一个分割(segmentation)算法，然后再识别。而CTC不要求训练数据的对齐，因此非常适合语音识别和手写文字识别这种问题，这里我会以语音识别为例介绍CTC，而后面我们会通过示例介绍使用CTC来进行验证码识别。



![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-1.png)

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-3.png)

接下来在正式介绍CTC的算法之前，我们引入一些记号更加形式化的描述CTC要解决的问题。首先我们假设输入序列X=[x1,x2,…,xT]，比如在语音识别中，它是T个帧，每一帧xt是39维的MFCC特征。输出序列是Y=[y1,y2,…,yU]。这个任务我们很难把它转化为简单的分类任务，因为：

- X和Y都是变长的
- X和Y的长度比也是变化的(X和Y的长度不存在简单的比例对应关系)
- 训练数据中没有X和Y的对齐

CTC可以解决这些问题，给定一个输入X，CTC可以对所有可能的Y计算P(Y|X)。有了这个概率，我们就可以推断最可能的输出或者计算某个Y的概率。在训练的时候，我们需要计算损失函数，并且通过梯度下降调整参数使得损失在训练数据上最小。为了实现训练，我们需要一种高效快速的方法来计算条件概率P(Y|X)，而且还要求它是可导的，这样我们才能计算梯度。而在预测的时候，给定输入X，我们需要计算最可能的Y。CTC虽然没有精确的算法来高效的计算最优路径，但是它提供近似的算法使得我们能在合理的时间内找到较优的路径。

## CTC算法详解

给定X时，CTC算法可以计算所有输出Y的概率。理解计算这个概率的关键是CTC怎么处理输入和输出的对齐。因此我们首先讨论输入和输出的对齐问题。

### 对齐

CTC算法是不需要对齐输入和输出的，为了计算给定X的条件下输出Y的概率，CTC会枚举所有可能的对齐方式然后把这些概率累积起来。要理解CTC算法，我们首先需要理解对齐。

在介绍CTC的对齐之前，我们先看看一种简单的对齐方式。我们通过一个例子来说明它。我们假设输入长度为6，输出Y=[c,a,t]。一种简单的对齐方法是给每一个输入都对应Y中的一个字符（而且保证顺序）。比如如下图所示是一种合法的对齐方式，其中x1,x2对应c，x3,x4,x5对应a，x6对应t。

这种简单的对齐有两个问题：

- 强制要求每个输入都对应实际的输出是不合理的，比如在语音识别中会有静音(silence)，这些输入不对应任何输出
- 没办法输出连续相同的字符，比如假设有一个单词caat，那么上面的对齐只能认为输出是cat。

为了解决上述问题，CTC引入了一个新的特殊符号ϵ，它表示空字符，在最后我们会去掉它。如下图所示，首先有些输入可以对应空字符，这样我们可以解决第一个问题。同样由于有了空字符，我们可以区分连续的字符。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-5.png)

如果输出有两个连续相同的字符，那么它们之间一定要有至少一个空字符，这样我们就可以区分hello和helo了。对于之前长度为6的输入，输出为cat的例子，下图是一些合法的和非法的CTC对齐的例子。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-6.png)

CTC对齐有如下一些特性。首先它是单调的，如果我们输入往前一步，那么输出可以保持不变，也可以往前一步。比如假设x1是c，与之对于的y是c，我们往前走一步，有可能x2还是c，那么y的输出是保持不变的。当然也可能x2是a了，那么y的输出也往前走一步变成ca。第二个特点就是输入与输出是多对一的关系，输出的c可以对于x1,x2两个输入，但一个输入x1只能对应一个输出。这个特性可以推出如下结论：输入序列的长度一定是大于等于输出长度的。

### 损失函数

有了CTC对齐之后，计算条件概率P(Y|X)就变得非常自然了，下图是计算过程的示意图，我们下面会详细介绍其计算过程。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-7.png)

在上图中，最上面是我们的输入序列，比如在语音识别中，输入是帧的序列，每一帧可以提取其MFCC作为其特征向量。然后我们可以把输入序列feed进一个RNN模型。这个RNN模型会计算每一个时刻t的输出的概率分布pt(a|X)，表示t时刻输出字符a的概率，这这个例子里可能的字符是{h,e,l,o,ϵ}。假设输入的长度为T，那么理论上有5^T中不同的对齐方式（路径），当然有些概率很低，我们可以忽略。这些路径中有一些的输出是一样的，比如都是”hello”，我们把它的概率加起来就得到了P(“hello”|X)的概率。

更加形式化地，假设一个输入输出对(X,Y)，我们有：
$$
P ( Y | X ) = \sum _ { A \ in\ A_{x,y}  }\prod _ { t - 1 } ^ { T } P _ { t } ( a _ { t } | X )
$$
在使用CTC的时候我们通常用RNN来估计每个时刻的输出pt(at|X)。因为RNN可以很好的建模序列标注问题，但是CTC并没有要求一定用什么样的模型。给定X和Y，如果我们直接遍历所有的路径，那么效率会非常低，因为路径会随着T指数增加。不过我们可以使用**动态规划**技术来提高计算效率，这项技术在HMM里也用到过。

因为在输出Y的任意两个字符之间都可以对应空字符（比如语音识别的任意两个音素直接都可以有silence），所有我们在Y的每个字符直接都插入空字符得到Z=[ϵ,y1,ϵ,y2,…,yU,ϵ]。假设αs,t表示输入序列的前s个字符X1:s和输出的前t个字符Z1:t对齐时所有合法路径的概率和。有了t时刻之前的α，我们就可以计算t时刻的α，这样我们就能使用动态规划算法。最后得到T时刻的α之后我们就可以得到P(Y|X)。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-8.png)

### 预测

模型训练好了之后，我们需要用它来预测最可能的结果。具体来说，我们需要解决如下问题：
$$
Y^*=\underset{Y}{\operatorname{argmax}} P(Y \mid X)
$$


最简单的方法是每一个时刻都选择概率最大的输出，这样可以得到概率最大的一条路径(一种对齐)：
$$
A^*=\underset{A}{\operatorname{argmax}} \prod_{t=1}^T p_t\left(a_t \mid X\right)
$$
最后我们把连续相同的字符合并，并去掉空字符就能得到最终的输出。对于有些应用，这种简单的方法是可以工作的，尤其是当模型的大部分概率集中在一条路径上的时候。但是另外一些应用可能有问题，因为一种输出可能对应多种可能的对齐，可能的情况是某种输出它的每种对齐分都不是特别高，但是加起来却很高。

举个例子，假设对齐[a,a,ϵ]和[a,a,a]的概率都比[b,b,b]小，按照上面的算法我们会输出b，但是实际上[a,a,ϵ]和[a,a,a]加起来的概率可能是大于[b,b,b]的，那么实际应该输出的是a。

我们可以使用一个改进版的Beam Search方法来搜索，虽然它不能保证找到最优解，但是我们可以调整beam的大小，beam越小，速度越快；beam越大，搜索的解越好。极限的情况是，如果beam是1那么它等价与前面的算法；如果beam是所有字母的个数，那么它会遍历所有路径，保证能找到最优解。

普通的Beam Search方法会在每个时刻保留最优的N条路径，然后在t+1时刻对这N条路径展开，然后从所有展开的路径中选择最优的N条路径,一直到最终时刻T。下图是使用普通Beam Search算法的示例。在图中，我们发现在t=3的时候，有两条路径的输出都是a(分别是[a,ϵ]和[ϵ,a])，它们(有可能)是可以合并的（请读者思考为什么是有可能而不是一定？）。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-12.png)

因此我们可以改进一些Beam Search算法，把相同输出的路径合并起来。这里的合并是把输出里相同的字符变成一个，并且去掉空字符，然后所有相同输出的概率累加起来。

在t=3的时刻，在下方，[b,a,ϵ]和[b,a,a]被合并成相同的结果[b,a]。另外需要注意的是t=3的时刻，上方[a]在扩展增加a的时候会输出两条路径[a,a]，与[a]。把两个a合并成一个这是显然的，但是不合并的路径需要注意。我们如果想在t=4时得到a-a。那么只有图中粗线条的一种路径([a,ϵ,a])，其它两条路径[a,a,a]和[ϵ,a,a]都是无法输出a-a的，它们只能输出a。

为了区分，我们需要在t=2到t=3的合并的时候记下哪些路径的最后一个字符是空，哪些不是。在上图的例子中路径[ϵ,a]和[a,a]的结尾不是空，而路径[a,ϵ]的结尾是空，因此当t=3到t=4值遇到a的时候，前两条路径只能输出a，而后一条路径既能输出a也能输出a-a。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-13.png)



![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-14.png)

因此我们可以再次改进搜索算法，如下图所示，在合并的时候，我们会记下以空结尾的路径的概率和。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-15.png)

在语音识别中，我们一般需要在加入一个语言模型来提高识别效果，我们可以很容易的把语言模型集成进来：
$$
Y^*=\underset{Y}{\operatorname{argmax}}(Y \mid X) \cdot p(Y)^\alpha \cdot L(Y)^\beta
$$


P(Y)就是语言模型，而L(Y)是一个语言模型长度的奖励，如果L(Y)是基于词的语言模型，那么L(Y)就是词的个数，如果L(Y)是基于字符(character)的语言模型，那么L(Y)就是字符的个数。因为越长的句子概率越小，如果不加这个奖励的话，语言模型总是会倾向于选择短的句子。超参数α和β通常通过交叉验证来选择。

## CTC算法的特性

### 条件独立

CTC经常被诟病的一个特点就是它的条件独立性。这个模型假设给定X的时候不同时刻的yt是独立的，这个假设对于很多序列标注问题来说是不合理的。假设一个语音是要说”三个A“，它有两种说法：”三个A(triple A)”;”AAA”。如果第一个输出是A，那么第二个输出A的概率应该变大；类似的如果第一个输出是t（英文的triple的t)，那么输出triple A的概率更大，如下图所示。但是CTC无法建模这种关系。

![img](C:\Users\Administrator\Documents\blogs\picture\CTC\ctc-16.png)

也就是说CTC是无法建模输出序列之间的依赖关系的（不是说它无法建模输入序列的依赖关系！），也就是它不会学到任何语言模型的知识。因此像前面所说的，我们一般会加入额外的一个语言模型。但换个角度，这其实并不是坏事！因为让CTC只学习声学特征，而把语言学特征交个单独的语言模型，这会让它切换到一个新的领域变得更简单——我们只需要换另外一个领域的语言模型就可以了。

## 对齐

CTC算法不需要训练数据对齐，它会把所有相同输出的对齐合并。虽然CTC要求输入X和输出Y严格对齐，但是具体怎么对齐它并没有在模型层面加任何限制，是把概率比较均匀的分配给所有可能的路径还是把概率集中的分配给某些路径，这是不能确定的。

CTC要求对齐的方式是单调的，这对于语音识别是合适的假设，但是对于其它的任务，比如机器翻译，这种对齐是不合适的。因为一个不同语言的语序是不同的，比如英语a friend of mine和我的朋友，在英语里，friend在mine之前，但是在汉语里”我的”在”朋友”之前。

CTC的另外一个要求就是输入和输出是多对一的，有的任务可以要求严格的一对一关系，比如词性标注，那CTC也是不合适的。另外它也无法表示输入与输出的多对一的关系。比如在英语中，th是一个音素，一个输入可能要对于th这两个输出，CTC也是无法表示这种关系的。

最后一个就是CTC要求输出比输入短，虽然这在语音识别是合理的假设，但是其它的任务可能就不一定。