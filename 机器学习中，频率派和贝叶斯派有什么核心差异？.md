在刚学习机器学习时，你肯定有产生这样的疑惑，为什么损失函数是这样设计的？为什么偏偏是最小二乘法，交叉熵？L1正则化和L2正则化又有什么区别？

我们下面将从**概率**角度，为这些损失函数的设计找到理论支撑。

下面将要介绍的是两种学派：**贝叶斯派和频率派**。在学习机器学习的过程中，应该听说过很多次这两个专业词汇，我的建议是，刚开始学不用过于深究，这不会影响你学习各种模型，当你了解完很多模型算法后，再回过头来看贝叶斯派和频率派，就会有种醍醐灌顶的感觉，你在每种模型上都可以找到它们的哲学思想、方法论。

首先要介绍一些概念

贝叶斯公式：
$$
 P(\theta \mid x)=\frac{P(x \mid \theta) P(\theta)}{P(x)} 
$$
