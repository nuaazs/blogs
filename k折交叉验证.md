# N折交叉验证的作用

## sdfsdkj 

### sfksjd k

$$
-\frac{\hbar^{2}}{2 \mu} \frac{\partial^{2} \Psi(x, t)}{\partial x^{2}}+U(x, t) \Psi(x, t)=i \hbar \frac{\partial \Psi(x, t)}{\partial t}
$$

### 概括



![image-20210907195321949](C:\Users\nuaazs\AppData\Roaming\Typora\typora-user-images\image-20210907195321949.png)

![](https://shengbucket.oss-cn-hangzhou.aliyuncs.com/pics/kLDku.jpg)



1. N折交叉验证有**两个用途**：模型评估、模型选择。
2. N折交叉**只是一种划分数据集的策略。**想知道它的**优势**，可以拿它和传统划分数据集的方式进行比较。它可以避免固定划分数据集的局限性、特殊性，这个优势在小规模数据集上更明显。
3. 把这种策略用于划分训练集和测试集，就可以进行模型评估；把这种策略用于划分训练集和验证集，就可以进行模型选择。
4. 不用N折交叉验证就不能进行模型评估和模型选择了吗？当然不是。只要有测试集，就能进行模型评估；只要有验证集，就能进行模型选择。所以N折交叉验证只是在做这两件事时的一种可选的优化手段。





之前做一个深度学习项目，因为数据集很小，实验室的学长建议用交叉验证的方法来避免过拟合。但是在学习相关资料的时候，发现很多地方对于“交叉验证“的方法的**说法不一致**：有些说法是把数据集分成 {训练集, 验证集, 测试集}，有些说法是只需要把数据集分成 {训练集, 验证集}。

实际上，交叉验证有多种用途。如果进行交叉验证的目的不一样，那么在实施交叉验证时的方法也会不一样。交叉验证的作用主要有两个：

- 模型选择
- 模型评估

## 用途一：模型选择

交叉验证最关键的作用是进行**模型选择**，也可以称为**超参数选择**。

在这种情况下，数据集需要划分成**训练集、验证集、测试集**三部分，训练集和验证集的划分采用N折交叉的方式。很多人会把验证集和测试集搞混，如果是这种情况，必须明确地区分验证集和测试集。

- **验证集**是在**训练过程中**用于检验模型的训练情况，从而确定合适的超参数；
- **测试集**是在**训练结束之后**，测试模型的泛化能力。

具体的过程是，首先在训练集和验证集上对多种模型选择（超参数选择）进行验证，选出平均误差最小的模型（超参数）。选出合适的模型（超参数）后，可以把训练集和验证集合并起来，在上面重新把模型训练一遍，得到最终模型，然后再用测试集测试其泛化能力。

对这种类型的交叉验证比较有代表性的解释有：台大李宏毅的《机器学习》课程、李飞飞的《CS231N计算机视觉》课程等。

![](https://shengbucket.oss-cn-hangzhou.aliyuncs.com/pics/fQGh6.jpg)

![](https://shengbucket.oss-cn-hangzhou.aliyuncs.com/pics/95CKx.jpg)



## 用途二：模型评估

交叉验证的另一个用途，就是模型是确定的，没有多个候选模型需要选，只是用交叉验证的方法来**对模型的performance进行评估**。

这种情况下，数据集被划分成**训练集、测试集**两部分，训练集和测试集的划分采用N折交叉的方式。这种情况下没有真正意义上的验证集，个人感觉这种方法叫做”交叉测试“更合理...

相比于传统的模型评估的方式（划分出固定的训练集和测试集），交叉验证的优势在于：避免由于数据集划分不合理而导致的问题，比如模型在训练集上过拟合，这种过拟合可能不是模型导致的，而是因为数据集划分不合理造成的。这种情况在用小规模数据集训练模型时很容易出现，所以**在小规模数据集上用交叉验证的方法评估模型更有优势**。

对这种类型的交叉验证比较有代表性的解释有：周志华《机器学习》。

![](https://shengbucket.oss-cn-hangzhou.aliyuncs.com/pics/nc6g2.jpg)

## 两种用途的关系

两种用途在本质上是一致的，模型评估可以看成是模型选择过程中的一个步骤：先对候选的每个模型进行评估，再选出评估表现最好的模型作为最终模型。

交叉验证的核心思想在于对数据集进行多次划分，对多次评估的结果取平均，从而消除单次划分时数据划分得不平衡而造成的不良影响。因为这种不良影响在小规模数据集上更容易出现，所以交叉验证方法在小规模数据集上更能体现出优势。

## 交叉验证与过拟合的关系

当用交叉验证进行**模型选择**时，可以从多种模型中选择出泛化能力最好的（即最不容易发生过拟合）的模型。从这个角度上讲，**交叉验证是避免发生过拟合的手段**。同样是解决过拟合的方法，交叉验证与正则化不同：**交叉验证**通过**寻找最佳模型**的方式来解决过拟合；而**正则化**则是通过**约束参数的范数**来解决过拟合。

当用交叉验证进行**模型评估**时，交叉验证不能解决过拟合问题，只能用来评估模型的performance。

## 交叉验证的优缺点

优点：获得对模型更合理更准确的评估，尤其是数据集很小时，更能体现出这个优势。

缺点：增加了计算量。

## 总结交叉验证的使用方法

- 如果当前有多个候选模型，想从中选出一个最合适的模型，就可以用交叉验证的方法进行模型选择，尤其是当数据集很小时。
- 如果当前只有一个模型，想获得对这个模型的performance最客观的评估，就可以用交叉验证的方法进行模型评估，尤其是当数据集很小时。